{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmit-ir/Tutotrial-Practical-LLMs/blob/main/LLM_Tutorial_Challenge2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URG6QxQ_17vp"
      },
      "outputs": [],
      "source": [
        "import requests  # Allows you to send HTTP requests, useful for interacting with APIs or web scraping\n",
        "import json  # Provides methods for working with JSON data\n",
        "import pandas as pd  # Provides data structures and functions needed to manipulate structured data\n",
        "import re  # Provides regular expression operations for text pattern\n",
        "import textwrap  # Used for formatting and wrapping text, useful for displaying text in a readable way\n",
        "\n",
        "from google.colab import (\n",
        "    userdata,\n",
        ")  # Provides access to user-specific information in Google Colab, used to access the user's secret API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_response(\n",
        "    prompt: str, model: str, verbose: int = VERBOSE, **model_kwargs\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Get a response from the OpenRouter API using the given prompt and model.\n",
        "    Make sure to set your OpenRouter API key in the environment variable\n",
        "    OPENROUTER_API_KEY. OpenRouter normalizes requests and responses across\n",
        "    providers. That is, you can use the same code to call different models from\n",
        "    different providers.\n",
        "    Args:\n",
        "        prompt (str): The prompt to send to the model.\n",
        "        model (str): The model to use.\n",
        "        verbose (int): Verbosity level for debugging.\n",
        "        **model_kwargs: Additional keyword arguments for the model.\n",
        "            - top_p: Top-p sampling parameter.\n",
        "            - temperature: Temperature parameter for sampling.\n",
        "            - frequency_penalty: Frequency penalty parameter.\n",
        "            - presence_penalty: Presence penalty parameter.\n",
        "            - repetition_penalty: Repetition penalty parameter.\n",
        "            - top_k: Top-k sampling parameter.\n",
        "    Note: The model_kwargs parameters are optional and will be set to default values if not provided.\n",
        "    Returns:\n",
        "        dict: The response from the model.\n",
        "    \"\"\"\n",
        "    # Check if model parameter is provided, if not, set a default value\n",
        "    top_p = model_kwargs.get(\"top_p\", 1)\n",
        "    temperature = model_kwargs.get(\"temperature\", 0.9)\n",
        "    frequency_penalty = model_kwargs.get(\"frequency_penalty\", 0)\n",
        "    presence_penalty = model_kwargs.get(\"presence_penalty\", 0)\n",
        "    repetition_penalty = model_kwargs.get(\"repetition_penalty\", 1)\n",
        "    top_k = model_kwargs.get(\"top_k\", 0)\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    response = requests.post(\n",
        "        url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
        "        headers={\"Authorization\": f\"Bearer {userdata.get('OPENROUTER_API_KEY')}\"},\n",
        "        data=json.dumps(\n",
        "            {\n",
        "                \"model\": model,\n",
        "                \"messages\": messages,\n",
        "                \"top_p\": top_p,\n",
        "                \"temperature\": temperature,\n",
        "                \"frequency_penalty\": frequency_penalty,\n",
        "                \"presence_penalty\": presence_penalty,\n",
        "                \"repetition_penalty\": repetition_penalty,\n",
        "                \"top_k\": top_k,\n",
        "            }\n",
        "        ),\n",
        "    )\n",
        "    if verbose > 0:\n",
        "        print(f\"Response status code: {response.status_code}\")\n",
        "    response_json = response.json()\n",
        "    # let's print how many tokens we used, it can be useful for cost estimation\n",
        "    if verbose > 0:\n",
        "        print(f\"Response usage: {response_json.get('usage')}\")\n",
        "    return response_json"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNvl2K8y83O5d7PMPRsG0ws",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
